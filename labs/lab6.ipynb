{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# MATH50003 (2023‚Äì24)\n",
    "# Lab 6: III.3 Cholesky Factorisation and III.4 Polynomial Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this lab we explore using LU, PLU and Cholesky factorisations, and\n",
    "implement algorithms for computing a Cholesky factorisation. We explore\n",
    "stability properties of these different factorisations, and see that the\n",
    "Cholesky factorisation is a robust way of determining if a matrix is symmetric\n",
    "postive definite.\n",
    "\n",
    "We also explore polynomial interpolation and regression, and see that when\n",
    "interpolating at an evenly spaced grid one can encounter issues with convergence.\n",
    "This is overcome via regression, but we are left with the question of how to\n",
    "solve the underlying least squares problems."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Learning Outcomes**\n",
    "\n",
    "Mathematical knowledge:\n",
    "\n",
    "1. Cholesky and reverse Cholesky factorisations, including for banded matrices.\n",
    "2. Vandermonde matrices and least squares.\n",
    "3. Issues with interpolation at evenly spaced points with functions with small radii of convergence.\n",
    "\n",
    "Coding knowledge:\n",
    "\n",
    "1. Using the `lu` and `cholesky` functions.\n",
    "2. Solving least squares problems via `\\`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We load the following packages:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using LinearAlgebra, Plots, Test"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### III.3 LU and Cholesky Factorisations"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "LU, PLU and Cholesky factorisations are closely related\n",
    "matrix factorisations that reduce a square matrix to a product of\n",
    "lower and upper triangular matrices, possibly with a permutation matrix.\n",
    "We will only focus on the practical usage of LU and PLU, without digging into the\n",
    "details of implementation. For the Cholesky factorisation we will look at implementation."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### III.3.1 LU Factorisation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "If $A ‚àà ùîΩ^{n √ó n}$ is a square matrix where $ùîΩ$ is a field ($‚Ñù$ or $‚ÑÇ$)\n",
    "then we can sometimes find lower and upper triangular matrices $L,U ‚àà ùîΩ^{n √ó n}$ such that\n",
    "$$\n",
    "A = LU.\n",
    "$$\n",
    "This is equivalent to Gaussian elimination but we will only focus on practical usage in this lab.\n",
    "This factorisation can be computed using the `lu` function, but as the default is a PLU factorisation we add a flag\n",
    "telling it not to use pivoting/permutations:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "A = [1.0 1 1;\n",
    "     2   4 8;\n",
    "     1   4 9]\n",
    "\n",
    "L,U = lu(A, NoPivot()) # NoPivot is a flag that tells lu to not use permutations"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This matches what we derived by hand in the notes and indeed:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@test A ‚âà L*U"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can use an LU factorisation to reduce solving a linear system to inverting triangular matrices:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "b = randn(3)\n",
    "c = L \\ b # computed using forward elimination (even though L is a Matrix, \\ detects it is lower triangular)\n",
    "x = U \\ c # computed using back substitution\n",
    "@test A \\ b ‚âà x"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "If a matrix has a zero on a pivot we know by equivalence to Gaussian elimination that an LU factorisation\n",
    "does not exist:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "A[1,1] = 0\n",
    "lu(A, NoPivot()) # throws an error"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "But even if it has a very small but non-zero entry we get huge errors:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "A[1,1] = 1E-14\n",
    "L,U = lu(A, NoPivot()) # Succeeds but suddenly U is on order of 2E14!"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "norm(A \\ b - U\\(L\\b)) # Very large error! A \\ b uses pivoting now."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**WARNING** The parantheses are important: algebra is left-associative so had we written `U\\L\\b` this would have been interpreted as\n",
    "`(L\\U) \\ b` which would have meant `inv(inv(L)*U)*b == U \\ (L*b)`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 1** For `A` defined above, consider setting  `A[1,1] = Œµ` for `Œµ = 10.0 ^ (-k)` for `k = 0,‚Ä¶,14`\n",
    "with the right-hand side `b = [1,2,3]`.\n",
    "Plot, scaling the $y$-axis logarithmically, the growth rate in the error of using LU compared to `\\`.\n",
    "Make a conjecture on how the error grows as $k ‚Üí ‚àû$.\n",
    "Hint: you can either allocate a vector of errors that is populated in a for-loop or write a simple comprehension."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Do a log-log plot for A with its 1,1 entry set to different Œµ and guess the growth rate."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 2(a)** Consider the Helmholtz equations\n",
    "$$\n",
    "\\begin{align*}\n",
    "u(0) &= 0 \\\\\n",
    "u(1) &= 0 \\\\\n",
    "u'' + k^2 u &= {\\rm e}^x\n",
    "\\end{align*}\n",
    "$$\n",
    "discretised with finite-differences to result in a tridiagonal system.\n",
    "Use the `lu` function without pivoting to\n",
    "compute the LU factorization of the tridiagonal matrix. What sparsity structure\n",
    "do you observe in `L` and `U`? Does this structure depend on $n$ or $k$?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Apply lu to the discretisation for Helmholtz derived in the last lab and investigate its structure."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## III.3.2 PLU Factorisation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In general it is necessary to use pivoting, a feature you have seen\n",
    "in Gaussian elimination but as Problem 1 demonstrates we need to do so even if we do not encounter\n",
    "a zero. This corresponds to a factorisation of the form\n",
    "$$\n",
    " A = P^‚ä§LU\n",
    "$$\n",
    "where $P$ is a permutation matrix, $L$ is lower triangular and $U$ is upper triangular.\n",
    "We compute this as follows, printing out the permutation:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "A = [0.1 1 1;\n",
    "     2   4 8;\n",
    "     1   4 9]\n",
    "\n",
    "L,U,œÉ = lu(A)\n",
    "œÉ"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The permutation matrix is encoded as a vector $œÉ$. More precisely, we have\n",
    "$$\n",
    "    P^‚ä§ ùêØ = ùêØ[œÉ]\n",
    "$$\n",
    "Thus we can solve a linear system by  first permuting the entries of the right-hand side:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "b = [10,11,12]\n",
    "bÃÉ = b[œÉ] # permute the entries to [b[2],b[3],b[1]]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And then inverting $L$ and $U$ as before:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "c = L \\ bÃÉ # invert L with forward substitution\n",
    "x = U \\ c # invert U with back substitution\n",
    "\n",
    "@test x == A \\ b # \\ also use PLU to do the solve so these exactly equal"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note in the following problems we will see that PLU is _usually_ stable but not always.\n",
    "Fortunately the set of matrices where it fails to be accurate has extremely small measure.\n",
    "The big _open problem_ in numerical linear algebra is to turn this observation into a precise statement."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 2(b)** Repeat Problem 2(a) but with a PLU factorisation.\n",
    "Are $L$ and $U$ still banded?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Check sparsity of PLU factorisation"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 3(a)** Complete the function  `badmatrix(n)` that returns the following $‚Ñ§^{n √ó n}$ matrix:\n",
    "$$\n",
    "  B_n := \\begin{bmatrix}\n",
    "      1      &&&& 1  \\\\\n",
    "      -1 & 1       &&& 1   \\\\\n",
    "      ‚ãÆ & ‚ã± & ‚ã±   && ‚ãÆ    \\\\\n",
    "      -1 & ‚ãØ & -1 & 1 & 1 \\\\\n",
    "      -1 & ‚ãØ & -1 & -1 & 1\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "That is: all entries below the diagonal are $-1$ whilst the diagonal and last column are $1$."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function badmatrix(n)\n",
    "    # TODO: make the \"bad matrix\" with `Int` entries defined above and return it\n",
    "\n",
    "end\n",
    "\n",
    "@test badmatrix(3) isa Matrix{Int}\n",
    "@test badmatrix(3) == [1 0 1; -1 1 1; -1 -1 1]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 3(b)** Does `lu` use pivoting with `badmatrix(n)`? Does it use\n",
    "pivoting with a small random perturbation (created via `randn(n,n)`)?"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Use `lu` on `badmatrix(n)` and a small perturbation to determine if it\n",
    "# is using pivoting."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 3(c)** We can test the accuracy of a method for inverting a matrix\n",
    "by applying the matrix and seeing how different it was from the input, eg.\n",
    "computing `norm(A*(A\\b) - b)`. This would be zero if everything was done with\n",
    "exact arithmetic. Plot the norm of this error for `b = randn(n)` for `bandmatrix(n)`\n",
    "and `badmatrix(n) + 1E-15*randn(n,n)` for `n = 25, 50, 75, 100` and\n",
    "compare the observed differences in accuracy of PLU."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: plot the error norm(A*(A\\b) - b) for the perturbed and unperturbed badmatrix(n).\n",
    "# What do you observe?"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## III.3.3 Cholesky factorisation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Cholesky factorisation is a special case of LU factorisation for the case\n",
    "when a matrix is symmetric positive definite (SPD). Hidden in the proof that a Cholesky factorisation\n",
    "exists if and only if the matrix is SPD is a simple algorithm for computing it:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function mycholesky(A)\n",
    "    T = eltype(A)\n",
    "    m,n = size(A)\n",
    "    if n ‚â† m\n",
    "        error(\"Matrix must be square\")\n",
    "    end\n",
    "    if A ‚â† A'\n",
    "        error(\"Matrix must be symmetric\")\n",
    "    end\n",
    "\n",
    "    L = LowerTriangular(zeros(T,n,n)) # a lower triangular matrix that at the end will satisfy L'L\n",
    "    A‚±º = copy(A)\n",
    "    for j = 1:n\n",
    "        Œ±,ùêØ = A‚±º[1,1],A‚±º[2:end,1]\n",
    "        if Œ± ‚â§ 0\n",
    "            error(\"Matrix is not SPD\") # this error would be a proof that the matrix is not SPD, if done rigorously\n",
    "        end\n",
    "        L[j,j] = sqrt(Œ±)\n",
    "        L[j+1:end,j] = ùêØ/sqrt(Œ±)\n",
    "\n",
    "        # induction part\n",
    "        K = A‚±º[2:end,2:end] # drop first row and column of A\n",
    "        A‚±º = K - ùêØ*ùêØ'/Œ±\n",
    "    end\n",
    "    L\n",
    "end\n",
    "\n",
    "A = Symmetric(rand(100,100) + 100I) # Symmetric takes in a matrix and produces a symmetric version using the upper-triangular part.\n",
    "L = mycholesky(A)\n",
    "@test A ‚âà L*L'"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "With exact arithmetic algorithm succeeds if and only if $A$ is symmetric positive definite.\n",
    "With floating point errors this is not necessarily the case. (One could run it with interval arithmetic\n",
    "but that would only prove a matrix is SPD if the algorithm succeeded, failure could be caused by\n",
    "rounding.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In practice one would normally use the inbuilt `cholesky` function as follows:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "LÃÉ = cholesky(A).L\n",
    "@test LÃÉ ‚âà L # our implementation matches (approximately) the high-performance implementation."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the following problem we consider a Cholesky factorisation for tridiagonal matrices. Since we are assuming the\n",
    "matrix is symmetric, we will use a special type `SymTridiagonal` that captures the symmetry.\n",
    "In particular, `SymTridiagonal(dv, ev) == Tridiagonal(ev, dv, ev)`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 4** Use `mycholesky` or `cholesky` to deduce if the following matrices are SPD.\n",
    "$$\n",
    "\\begin{bmatrix} 1 & -1  \\\\\n",
    "-1 & 3\n",
    "\\end{bmatrix}, \\begin{bmatrix} 1 & 2 & 2  \\\\\n",
    "2 & 1 & 2\\\\\n",
    "2 & 2 & 1\n",
    "\\end{bmatrix}, \\begin{bmatrix} 3 & 2 & 1  \\\\\n",
    "2 & 4 & 2\\\\\n",
    "1 & 2 & 5\n",
    "\\end{bmatrix},\n",
    "\\begin{bmatrix} 4 & 2 & 2 & 1  \\\\\n",
    "2 & 4 & 2 & 2\\\\\n",
    "2 & 2 & 4 & 2 \\\\\n",
    "1 & 2 & 2 & 4\n",
    "\\end{bmatrix}\n",
    "$$"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: Check if you got PS6 Q1 correct using a computer to do the Cholesky factorisation."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 5** Complete the following\n",
    "implementation of `mycholesky` to return a `Bidiagonal` cholesky factor in $O(n)$ operations."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# return a Bidiagonal L such that L'L == A (up to machine precision)\n",
    "# You are allowed to change A\n",
    "function mycholesky(A::SymTridiagonal)\n",
    "    d = A.dv # diagonal entries of A\n",
    "    u = A.ev # sub/super-diagonal entries of A\n",
    "    T = float(eltype(A)) # return type, make float in case A has Ints\n",
    "    n = length(d)\n",
    "    ld = zeros(T, n) # diagonal entries of L\n",
    "    ll = zeros(T, n-1) # sub-diagonal entries of L\n",
    "\n",
    "    # TODO: populate the diagonal entries ld and the sub-diagonal entries ll\n",
    "    # of L so that L*L' ‚âà A\n",
    "\n",
    "\n",
    "    Bidiagonal(ld, ll, :L)\n",
    "end\n",
    "\n",
    "n = 1000\n",
    "A = SymTridiagonal(2*ones(n),-ones(n-1))\n",
    "L = mycholesky(A)\n",
    "@test L isa Bidiagonal\n",
    "@test L*L' ‚âà A"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## III.4 Polynomial Interpolation and Regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now explore the practical usage of polynomial interpolation and regression.\n",
    "In particular we will see that polynomial interpolation may fail as the number\n",
    "of points becomes large."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### III.4.1 Polynomial Interpolation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A quick-and-dirty way to to do interpolation is to invert the Vandermonde matrix.\n",
    "That is, for\n",
    "$$\n",
    "p(x) = ‚àë_{k = 0}^{n-1} c_k x^k\n",
    "$$\n",
    "and $x_1, ‚Ä¶, x_n ‚àà ‚Ñù$, we choose $c_k$ so that $p(x_j) = f(x_j)$ for\n",
    "$j = 1, ‚Ä¶, n$. We do so by creating the square Vandermonde matrix\n",
    "$$\n",
    "V := \\begin{bmatrix} 1 & x_1 & ‚ãØ & x_1^{n-1} \\\\\n",
    "                    ‚ãÆ & ‚ãÆ & ‚ã± & ‚ãÆ \\\\\n",
    "                    1 & x_n & ‚ãØ & x_n^{n-1}\n",
    "                    \\end{bmatrix}.\n",
    "$$\n",
    "If the function samples are\n",
    "$$\n",
    " ùêü = \\begin{bmatrix} f(x_1) \\\\ ‚ãÆ \\\\ f(x_n) \\end{bmatrix}\n",
    "$$\n",
    "then the coefficients of the interpolatory polynomial\n",
    "$$\n",
    "      ùêú = \\begin{bmatrix}\n",
    "          c_0 \\\\ ‚ãÆ \\\\ c_{n-1} \\end{bmatrix}\n",
    "$$\n",
    "must satisfy $V ùêú = ùêü$.  Thus inverting the Vandermonde matrix tells us the coefficients."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we see an example of this using `n` evenly spaced points:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "f = x -> cos(10x)\n",
    "n = 5\n",
    "ùê± = range(0, 1; length=n) # evenly spaced points (BAD for interpolation)\n",
    "V =  [ùê±[j]^k for j = 1:n, k = 0:n-1] # Vandermonde matrix, also can be written as x .^ (0:n)'\n",
    "ùêü = f.(ùê±) # evaluate f at x[k], equivalent to [f(x[k]) for k = 1:n]\n",
    "ùêú = V \\ ùêü # invert the Vandermonde matrix and determine the coefficients\n",
    "p = x -> dot(ùêú, x .^ (0:n-1)) # take a dot product with monomials x .^ 0:n-1 == [x^j for j=0:n-1]\n",
    "@test p.(ùê±) ‚âà V * ùêú # evaluating the polynomial on x is the same as applying V\n",
    "\n",
    "\n",
    "ùê† = range(0,1; length=1000) # plotting grid, sample a lot more than interpolation points\n",
    "\n",
    "# To evaluate a polynomial on the plotting grid its faster to create the rectangular Vandermonde matrix associated with that grid:\n",
    "V_g = [ùê†[j]^k for j = 1:length(ùê†), k = 0:n-1]\n",
    "\n",
    "plot(ùê†, f.(ùê†); label=\"function\")\n",
    "plot!(ùê†, V_g*ùêú; label=\"interpolation\")\n",
    "scatter!(ùê±, f.(ùê±); label=\"samples\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Whether an interpolation is actually close to a function is a subtle question,\n",
    "involving properties of the function, distribution of the sample points $x_1,‚Ä¶,x_n$,\n",
    "and round-off error.\n",
    "A classic example is:\n",
    "$$\n",
    "  f_M(x) = {1 \\over M x^2 + 1}\n",
    "$$\n",
    "where the choice of $M$ can dictate whether interpolation at evenly spaced points converges."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "-------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 6(a)** Interpolate $1/(4x^2+1)$ and $1/(25x^2 + 1)$ at an evenly spaced grid of $n$\n",
    "points, plotting the solution at a grid of $1000$ points. For $n = 50$ does your interpolation match\n",
    "the true function?  Does increasing $n$ to 400 improve the accuracy? How about using `BigFloat`?\n",
    "Hint: make sure to make your `range` be `BigFloat` valued, e.g., `range(big(-1), big(1); length=n)`."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: interpolate 1/(10x^2 + 1) and 1/(25x^2 + 1) at $n$ evenly spaced points, plotting both solutions evaluated at\n",
    "# the plotting grid with 1000 points, for $n = 50$ and $400$."
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "------"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### III.4.2 Polynomial regression"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "To overcome issues with interpolation we will instead use regression: use more points than\n",
    "the degree of the polynomial. As an example, suppose we want to fit noisy data by a quadratic\n",
    "$$\n",
    "p(x) = c‚ÇÄ + c‚ÇÅ x + c‚ÇÇ x^2\n",
    "$$\n",
    "That is, we want to choose $c‚ÇÄ,c‚ÇÅ,c‚ÇÇ$ at data samples $x_1, ‚Ä¶, x_m$ so that the following is true:\n",
    "$$\n",
    "c‚ÇÄ + c‚ÇÅ x_j + c‚ÇÇ x_j^2 ‚âà f_j\n",
    "$$\n",
    "where $f_j$ are given by data. We can reinterpret this as a least squares problem: minimise the norm\n",
    "$$\n",
    "\\left\\| \\begin{bmatrix} 1 & x_1 & x_1^2 \\\\ ‚ãÆ & ‚ãÆ & ‚ãÆ \\\\ 1 & x_m & x_m^2 \\end{bmatrix}\n",
    "\\begin{bmatrix} p‚ÇÄ \\\\ p‚ÇÅ \\\\ p‚ÇÇ \\end{bmatrix} - \\begin{bmatrix} f_1 \\\\ ‚ãÆ \\\\ f_m \\end{bmatrix} \\right \\|\n",
    "$$\n",
    "When a matrix is rectangular `\\` solves a least squares problem for us:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "m,n = 100,3\n",
    "\n",
    "ùê± = range(0,1; length=m) # 100 points\n",
    "ùêü = 2 .+ ùê± .+ 2ùê±.^2 .+ 0.1 .* randn.() # Noisy quadratic samples, built with broadcast notation.\n",
    "\n",
    "V = ùê± .^ (0:2)'  # 100 x 3 Vandermonde matrix, equivalent to [ones(m) x x.^2]\n",
    "\n",
    "ùêú = V \\ ùêü # coefficients are, very roughly, [2,1,2]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can visualise the fit:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ùê† =range(0, 1; length=1000)\n",
    "\n",
    "p = x -> ùêú[1] + ùêú[2]x + ùêú[3]x^2\n",
    "\n",
    "scatter(ùê±, ùêü; label=\"samples\", legend=:bottomright)\n",
    "plot!(ùê†, p.(ùê†); label=\"quadratic\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "-----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Problem 6(b)** Repeat the previous problem but now using _least squares_: instead of interpolating,\n",
    "use least squares on a large grid: choose the coefficients of a degree $(n-1)$ polynomial so that\n",
    "$$\n",
    "    \\left\\| \\begin{bmatrix} p(x_1) \\\\ ‚ãÆ \\\\ p(x_m) \\end{bmatrix} - \\begin{bmatrix} f(x_1) \\\\ ‚ãÆ \\\\ f(x_m) \\end{bmatrix} \\right \\|.\n",
    "$$\n",
    "is minimised, where $n = 50$ and $m = 500$.\n",
    "Does this improve the accuracy near the endpoints? Do you think convergence for a least squares approximation\n",
    "is dictated by the radius of convergence of the corresponding Taylor series?\n",
    "Hint: use the rectangular Vandermonde matrix to setup the Least squares system."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# TODO: approximate 1/(10x^2 + 1) and 1/(25x^2 + 1) using a least squares system where the"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  },
  "kernelspec": {
   "name": "julia-1.10",
   "display_name": "Julia 1.10.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}
