
\section{Dual Numbers}
In this chapter we introduce a mathematically beautiful  alternative to divided differences for computing derivatives: \emph{dual numbers}. As we shall see, these are a commutative ring that \emph{exactly} compute derivatives, which when implemented in floating point give very high-accuracy approximations to derivatives. They underpin forward-mode \href{https://en.wikipedia.org/wiki/Automatic_differentiation}{automatic differentation}. Automatic differentiation  is a basic tool in Machine Learning for computing gradients necessary for training neural networks.

\begin{definition}[Dual numbers] Dual numbers $\ensuremath{\bbD}$ are a commutative ring (over $\ensuremath{\bbR}$) generated by $1$ and $\ensuremath{\epsilon}$ such that $\ensuremath{\epsilon}^2 = 0$. Dual numbers are typically written as $a + b \ensuremath{\epsilon}$ where $a$ and $b$ are real. \end{definition}

This is very much analoguous to complex numbers, which are a field generated by $1$ and $\I$ such that $\I^2 = -1$. Compare multiplication of each number type:
\meeq{
(a + b \I) (c + d \I) = ac + (bc + ad) \I + bd \I^2 = ac -bd + (bc + ad) \I \ccr
(a + b \ensuremath{\epsilon}) (c + d \ensuremath{\epsilon}) = ac + (bc + ad) \ensuremath{\epsilon} + bd \ensuremath{\epsilon}^2 = ac  + (bc + ad) \ensuremath{\epsilon} 
}
And just as we view $\ensuremath{\bbR} \ensuremath{\subset} \ensuremath{\bbC}$ by equating $a \ensuremath{\in} \ensuremath{\bbR}$ with $a + 0\I \ensuremath{\in} \ensuremath{\bbC}$, we can view $\ensuremath{\bbR} \ensuremath{\subset} \ensuremath{\bbD}$ by equating $a \ensuremath{\in} \ensuremath{\bbR}$ with $a + 0{\rm \ensuremath{\epsilon}} \ensuremath{\in} \ensuremath{\bbD}$.

\subsection{Differentiating polynomials}
Applying a polynomial to a dual number $a + b \ensuremath{\epsilon}$ tells us the derivative at $a$:

\begin{theorem}[polynomials on dual numbers] Suppose $p$ is a polynomial. Then
\[
p(a + b \ensuremath{\epsilon}) = p(a) + b p'(a) \ensuremath{\epsilon}
\]
\end{theorem}
\textbf{Proof}

It suffices to consider $p(x) = x^n$ for $n \ensuremath{\geq} 1$ as other polynomials follow from linearity. We proceed by induction: The case $n = 1$ is trivial. For $n > 1$ we have 
\[
(a + b \ensuremath{\epsilon})^n = (a + b \ensuremath{\epsilon}) (a + b \ensuremath{\epsilon})^{n-1} = (a + b \ensuremath{\epsilon}) (a^{n-1} + (n-1) b a^{n-2} \ensuremath{\epsilon}) = a^n + b n a^{n-1} \ensuremath{\epsilon}.
\]
\ensuremath{\QED}

\begin{example}[differentiating polynomial] Consider computing $p'(2)$ where
\[
p(x) = (x-1)(x-2) + x^2.
\]
We can use Dual numbers to differentiating, avoiding expanding in monomials or rules of differentiating:
\[
p(2+\ensuremath{\epsilon}) = (1+\ensuremath{\epsilon})\ensuremath{\epsilon} + (2+\ensuremath{\epsilon})^2 = \ensuremath{\epsilon} + 4 + 4\ensuremath{\epsilon} = 4 + \underbrace{5}_{p'(2)}\ensuremath{\epsilon}
\]
\end{example}

\subsection{Differentiating other functions}
We can extend real-valued differentiable functions to dual numbers in a similar manner. First, consider a standard function with a Taylor series (e.g. ${\rm cos}$, ${\rm sin}$, ${\rm exp}$, etc.)
\[
f(x) = \ensuremath{\sum}_{k=0}^\ensuremath{\infty} f_k x^k
\]
so that $a$ is inside the radius of convergence. This leads naturally to a definition on dual numbers:
\meeq{
f(a + b \ensuremath{\epsilon}) = \ensuremath{\sum}_{k=0}^\ensuremath{\infty} f_k (a + b \ensuremath{\epsilon})^k = f_0 + \ensuremath{\sum}_{k=1}^\ensuremath{\infty} f_k (a^k + k a^{k-1} b \ensuremath{\epsilon}) = \ensuremath{\sum}_{k=0}^\ensuremath{\infty} f_k a^k +  \ensuremath{\sum}_{k=1}^\ensuremath{\infty} f_k k a^{k-1} b \ensuremath{\epsilon}  \ccr
  = f(a) + b f'(a) \ensuremath{\epsilon}
}
More generally, given a differentiable function we can extend it to dual numbers:

\begin{definition}[dual extension] Suppose a real-valued function $f$ is differentiable at $a$. If
\[
f(a + b \ensuremath{\epsilon}) = f(a) + b f'(a) \ensuremath{\epsilon}
\]
then we say that it is a \emph{dual extension at} $a$.

Thus, for basic functions we have natural extensions:


\begin{align*}
\exp(a + b \ensuremath{\epsilon}) &:= \exp(a) + b \exp(a) \ensuremath{\epsilon} \\
\sin(a + b \ensuremath{\epsilon}) &:= \sin(a) + b \cos(a) \ensuremath{\epsilon} \\
\cos(a + b \ensuremath{\epsilon}) &:= \cos(a) - b \sin(a) \ensuremath{\epsilon} \\
\log(a + b \ensuremath{\epsilon}) &:= \log(a) + {b \over a} \ensuremath{\epsilon} \\
\sqrt{a+b \ensuremath{\epsilon}} &:= \sqrt{a} + {b \over 2 \sqrt{a}} \ensuremath{\epsilon} \\
|a + b \ensuremath{\epsilon}| &:= |a| + b\, {\rm sign} a\, \ensuremath{\epsilon}
\end{align*}
provided the function is differentiable at $a$. Note the last example does not have a convergent Taylor series (at 0) but we can still extend it where it is differentiable.

Going further, we can add, multiply, and compose such functions:

\begin{lemma}[product and chain rule] If $f$ is a dual extension at $g(a)$ and $g$ is a dual extension at $a$, then $q(x) := f(g(x))$ is a dual extension at $a$. If $f$ and $g$ are dual extensions at $a$ then  $r(x) := f(x) g(x)$ is also dual extensions at $a$. In other words:
\meeq{
q(a+b \ensuremath{\epsilon}) = q(a) + b q'(a) \ensuremath{\epsilon} \\
r(a+b \ensuremath{\epsilon}) = r(a) + b r'(a) \ensuremath{\epsilon}
}
\end{lemma}
\textbf{Proof} For $q$ it follows immediately:
\meeq{
q(a + b \ensuremath{\epsilon}) = f(g(a + b \ensuremath{\epsilon})) = f(g(a) + b g'(a) \ensuremath{\epsilon}) \ccr
= f(g(a)) + b g'(a) f'(g(a))\ensuremath{\epsilon} = q(a) + b q'(a) \ensuremath{\epsilon}.
}
For $r$ we have
\meeq{
r(a + b \ensuremath{\epsilon}) = f(a+b \ensuremath{\epsilon} )g(a+b \ensuremath{\epsilon} )= (f(a) + b f'(a) \ensuremath{\epsilon})(g(a) + b g'(a) \ensuremath{\epsilon}) \\
= f(a)g(a) + b (f'(a)g(a) + f(a)g'(a)) \ensuremath{\epsilon} = r(a) +b r'(a) \ensuremath{\epsilon}.
}
\end{definition}

A simple corollary is that any function defined in terms of addition, multiplication, composition, etc. of functions that are dual with differentiation will be differentiable via dual numbers.

\begin{example}[differentiating non-polynomial]

Consider $f(x) =  \exp(x^2 + \E^x)$ by evaluating on the duals:
\[
f(1 + \ensuremath{\epsilon}) = \exp(1 + 2\ensuremath{\epsilon} + \E + \E \ensuremath{\epsilon}) =  \exp(1 + \E) + \exp(1 + \E) (2 + \E) \ensuremath{\epsilon}
\]
and therefore we deduce that
\[
f'(1) = \exp(1 + \E) (2 + \E).
\]
\end{example}



